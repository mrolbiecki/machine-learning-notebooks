{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc84999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data.csv', sep=';')\n",
    "X = df.drop(['Class', 'Output'], axis=1)\n",
    "y = df['Output']\n",
    "\n",
    "# Function to evaluate models using cross-validation (copied from original notebook)\n",
    "def evaluate_model(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Calculate cross-validation scores\n",
    "    cv_r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    cv_neg_mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert negative MSE to RMSE\n",
    "    cv_rmse_scores = np.sqrt(-cv_neg_mse_scores)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Alpha: {model.alpha:.8f}\")\n",
    "    print(f\"Mean CV R²: {cv_r2_scores.mean():.4f} ± {cv_r2_scores.std():.4f}\")\n",
    "    print(f\"Mean CV RMSE: {cv_rmse_scores.mean():.4f} ± {cv_rmse_scores.std():.4f}\")\n",
    "    \n",
    "    return cv_r2_scores.mean(), cv_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Test a wide range of alpha values for Lasso\n",
    "alpha_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"\\nTesting Lasso with alpha = {alpha}\")\n",
    "    lasso_model = Lasso(alpha=alpha, max_iter=10000)\n",
    "    r2, rmse = evaluate_model(lasso_model, X_scaled, y)\n",
    "    \n",
    "    # Check how many coefficients are exactly zero\n",
    "    lasso_model.fit(X_scaled, y)\n",
    "    n_nonzero = np.sum(lasso_model.coef_ != 0)\n",
    "    n_zero = len(lasso_model.coef_) - n_nonzero\n",
    "    print(f\"Number of non-zero coefficients: {n_nonzero} out of {len(lasso_model.coef_)}\")\n",
    "    print(f\"Number of coefficients set to zero: {n_zero}\")\n",
    "    \n",
    "    results.append({\n",
    "        'alpha': alpha,\n",
    "        'r2': r2,\n",
    "        'rmse': rmse,\n",
    "        'nonzero_coefs': n_nonzero,\n",
    "        'zero_coefs': n_zero\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a250e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plot the effect of alpha on R2 and RMSE\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for R2\n",
    "ax1.plot(results_df['alpha'], results_df['r2'], 'o-')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_title('Effect of Alpha on R² Score')\n",
    "ax1.set_xlabel('Alpha (log scale)')\n",
    "ax1.set_ylabel('R² Score')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot for RMSE\n",
    "ax2.plot(results_df['alpha'], results_df['rmse'], 'o-')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_title('Effect of Alpha on RMSE')\n",
    "ax2.set_xlabel('Alpha (log scale)')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66494256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the effect of alpha on the number of non-zero coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['alpha'], results_df['nonzero_coefs'], 'o-')\n",
    "plt.xscale('log')\n",
    "plt.title('Effect of Alpha on Number of Non-Zero Coefficients')\n",
    "plt.xlabel('Alpha (log scale)')\n",
    "plt.ylabel('Number of Non-Zero Coefficients')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best alpha value\n",
    "best_alpha_idx = results_df['r2'].idxmax()\n",
    "best_alpha = results_df.loc[best_alpha_idx, 'alpha']\n",
    "best_r2 = results_df.loc[best_alpha_idx, 'r2']\n",
    "best_rmse = results_df.loc[best_alpha_idx, 'rmse']\n",
    "best_nonzero = results_df.loc[best_alpha_idx, 'nonzero_coefs']\n",
    "\n",
    "print(f\"Best alpha value: {best_alpha}\")\n",
    "print(f\"Best R²: {best_r2:.4f}\")\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "print(f\"Number of non-zero coefficients with best alpha: {best_nonzero}\")\n",
    "\n",
    "# Compare with the default Lasso model used in the original notebook\n",
    "default_lasso = Lasso()\n",
    "print(f\"\\nDefault Lasso alpha: {default_lasso.alpha}\")\n",
    "\n",
    "# Train a Lasso model with the best alpha\n",
    "best_lasso = Lasso(alpha=best_alpha, max_iter=10000)\n",
    "best_lasso.fit(X_scaled, y)\n",
    "\n",
    "# Examine top coefficients from the best Lasso model\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': best_lasso.coef_\n",
    "})\n",
    "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features by coefficient magnitude:\")\n",
    "print(coef_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfa08a",
   "metadata": {},
   "source": [
    "## Why Lasso Performs Poorly in the Original Notebook\n",
    "\n",
    "Based on the experiments above, we can identify several reasons why Lasso performs poorly in the original regression notebook:\n",
    "\n",
    "1. **Default Alpha Value**: The default alpha value in scikit-learn's Lasso implementation is 1.0, which appears to be too high for this dataset. This causes excessive penalization, leading to many coefficients being reduced to exactly zero.\n",
    "\n",
    "2. **Feature Sparsity**: With the default alpha, Lasso has eliminated most of the features (set their coefficients to zero), retaining only a small subset of features that may not capture the complexity of the relationship between predictors and the target variable.\n",
    "\n",
    "3. **Regularization Strength**: While regularization is useful for preventing overfitting, the penalty applied by the default Lasso model is too aggressive for this dataset, resulting in an underfitted model with poor predictive performance.\n",
    "\n",
    "4. **Scaling Issues**: Even though the data was scaled before applying Lasso in the original notebook, the default alpha might still be inappropriate for the scale of the predictors or the scale of the target variable.\n",
    "\n",
    "5. **Nature of the Relationship**: The target variable might depend on many features with small contributions rather than a few with large contributions, which is contrary to Lasso's assumption of sparsity.\n",
    "\n",
    "To improve Lasso's performance, we need to tune the alpha parameter to find the optimal regularization strength. A smaller alpha value allows more features to contribute to the prediction, potentially leading to better performance for this specific dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
